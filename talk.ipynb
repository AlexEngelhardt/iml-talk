{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Convert this talk to a HTML preserntation via  \n",
    "`jupyter nbconvert talk.ipynb --to slides`\n",
    "\n",
    "https://medium.com/@mjspeck/presenting-code-using-jupyter-notebook-slides-a8a3c3b59d67"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages, prepare data\n",
    "# (TODO paste the file in here later again. I just don't like scrolling all the time while drafting this notebook)\n",
    "\n",
    "%run setup.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![title](img/title.jpg)\n",
    "\n",
    "- <img src=\"img/twitter.svg\" style=\"height: 20px; float: left\" /> &nbsp; @eng_elhardt\n",
    "- <img src=\"img/github.svg\" style=\"height: 20px; float: left\" /> &nbsp; AlexEngelhardt (slides: https://github.com/AlexEngelhardt/iml-talk)\n",
    "- Longer blog post available at https://www.alpha-epsilon.de/blog/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Outline\n",
    "\n",
    "- Intro: Problems in ML models\n",
    "- Interpretable Machine Learning (IML) / Explainable AI (XAI)\n",
    "- How to achieve interpretability\n",
    "  - 1: Use interpretable models\n",
    "  - 2: Post-hoc model-agnostic methods\n",
    "- Data & Model\n",
    "- Model-agnostic methods\n",
    "  - Taxonomy\n",
    "  - Permutation Feature Importance\n",
    "  - Partial Dependence Plots\n",
    "  - TODO Shapley values / SHAP / LIME\n",
    "- Other methods not covered here\n",
    "- The future of IML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Intro: Problems in ML models\n",
    "\n",
    "- We like automatization\n",
    "- ML models automatize easy decisions\n",
    "- $\\Rightarrow$ we like ML\n",
    "- But: They are not pure advantage, but come with a few problems:\n",
    "\n",
    "### Problem 1: Fairness\n",
    "\n",
    "Story source: https://appsilon.com/please-explain-black-box/\n",
    "\n",
    "- In October 2018 world headlines reported about [Amazon AI recruiting tool](https://www.theguardian.com/technology/2018/oct/10/amazon-hiring-ai-gender-bias-recruiting-engine) that favored men. Amazon’s model was trained on biased data that were skewed towards male candidates. It has built rules that penalized resumes that included the word “women’s”.\n",
    "- Solution: PFI\n",
    "\n",
    "### Problem 2: Understanding\n",
    "\n",
    "- Many of us ultimately want to use datasets to extract scientific knowledge. A 98% accurate Random Forest is no good if we can't extract an explanation from the model. (Roscher 2019)\n",
    "- Scientific disciplines (e.g biology) use more and more ML for producing scientific outcomes. Their ultimate goal is not a correct model, but *knowledge*. IML extracts knowledge from a trained model.\n",
    "- Solution: PDPs\n",
    "\n",
    "### Problem 3: Explainability and Debugging\n",
    "\n",
    "- In February 2019 the Polish government added an amendment to a banking law that gives a customer a right to receive an explanation in case of a negative credit decision. It’s one of the direct consequences of implementing GDPR in EU. This means that a bank needs to be able to explain why the loan wasn’t granted if the decision process was automatic.\n",
    "- The EU's GDPR states: \"[the data subject should have] the right ... to obtain an explanation of the decision reached\". \n",
    "\n",
    "- Debugging and auditing (why does my model misclassify all <18 year olds?) is only possible when a model can be interpreted. An interpretation for a wrong prediction helps to understand the cause of the error and point you to what kind of additional training data you'll need.  Knowing *why* a model made a decision helps you to learn more about the problem, the data, and the reason why a model might fail.\n",
    "  - Also, if you understand your model well, you're better equipped for feature engineering, or even deciding to replace your model with a different one.\n",
    "\n",
    "<img src=\"img/husky-vs-wolf-LIME-paper.png\" style=\"height: 200px\" />\n",
    "\n",
    "- Solution: Local method. Shapley Values or SHAP or LIME or Counterfactual Examples\n",
    "- Solution: Get more pictures from Huskys in Alaska"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Lesson\n",
    "\n",
    "- Lesson: The need emerges to be able to look under the hood of machine learning models and *understand* their behavior.\n",
    "- This talk aims to be an introduction into the field and its methods.\n",
    "- Because our loss function is often just one part of what we really want to optimize¹. Additional criteria that are not covered by the loss function:\n",
    "  - fairness, explainability (as mentioned before),\n",
    "    - This might also increase social acceptance of AI models\n",
    "  - but also safety: You want to be 100% certain the abstraction for \"cyclist\" a DL driving model learned is correct. Imagine the model learned to \"see\" two wheels, then you'd run over bikes with side bags.\n",
    "- These criteria often cannot be quantified. E.g. we can't enumerate and write all unit tests required to let an autonomous car drive completely safely.\n",
    "- Interpretability is a popular fallback: If the system can /explain/ its reasoning, we can verify whether that reasoning makes sense with respect to these auxiliary criteria.\n",
    "    \n",
    "¹ Doshi-Velez et al., 2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Interpretable Machine Learning (IML) / Explainable AI (XAI)\n",
    "\n",
    "> \"Interpretability is the degree to which a human can understand the cause of a decision\"\n",
    ">\n",
    "> -- Miller, Tim. \"Explanation in artificial intelligence: Insights from the social sciences.\" [arXiv:1706.07269](https://arxiv.org/abs/1706.07269)\n",
    "\n",
    "- A relatively young field, changes quickly, diverse terminology, research papers at high speed\n",
    "  - Theory and nomenclature is not yet unified.\n",
    "    - cf. https://twitter.com/mattia_ferrini/status/1164124764392304640\n",
    "- This talk is based on Christoph Molnar: Interpretable Machine Learning\n",
    "  - Available free at https://christophm.github.io/interpretable-ml-book/\n",
    "  - R-package [iml](https://cran.r-project.org/web/packages/iml/index.html)\n",
    "    - A port to Python would be great!\n",
    "\n",
    "<img src=\"img/iml-book.jpg\" style=\"height: 200px\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# How to achieve interpretability\n",
    "\n",
    "We use IML because we want to be able to *trust* the predictions.\n",
    "\n",
    "- Option 1: Use interpretable models\n",
    "- Option 2: Use black-box models and post-hoc interpretation methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Option 1: Use interpretable models\n",
    "\n",
    "- Models are intrinsically interpretable because they are heavily constrained. Either to linear relationships (like LM) or to monotonous relationships (like logistic regression; they make it easier to understand a relationship) (Molnar pg 49)\n",
    "- like LM\n",
    "\t - Always a nice first choice :3\n",
    "\t - disadvantages: Molnar pg69\n",
    "\t   - can be unintuitive: rent ~ qm + #rooms, beta_#rooms will be negative!\n",
    "- Or decision trees\n",
    "\t - They shine when there are nonlinear effects and/or interactions between features.\n",
    "\t   - TODO do we need to introduce interactions? If so, do it here. Maybe in the blogpost yes, but talk no (time :()\n",
    "     - They have an inherent feature importance metric: The total node purity improvement (Molnar pg. 107)\n",
    "     - disadvantages: Molnar pg108\n",
    "\t   - fail at linear relationships\n",
    "\t   - very unstable: perturb data, entirely different tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Option 2: Use black-box models and post-hoc interpretation methods\n",
    "\n",
    "- Simple, interpretable models (t-tests, LM) are good when you want simple interpretability and have small datasets: E.g. medicine in the 80s.\n",
    "- But: \n",
    "\t - Because interpretable models come with assumptions, i.e. they are not flexible enough for the real world (pg. 300, Molnar)\n",
    "\t - Thus, interpretable models usually perform worse (this gets more true for bigger datasets, which has of course been the recent development)\n",
    "- \"Black Box\" informally: A model that cannot be understood by looking at its parameters. Linear Model vs. Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Data\n",
    "\n",
    "- Bike sharing!\n",
    "- aggregated to daily averages (sums for the `count` variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>year</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weather</th>\n",
       "      <th>temp</th>\n",
       "      <th>feel_temp</th>\n",
       "      <th>humidity</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>days_since_start</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>autumn</td>\n",
       "      <td>2011</td>\n",
       "      <td>no</td>\n",
       "      <td>saturday</td>\n",
       "      <td>no</td>\n",
       "      <td>clear</td>\n",
       "      <td>19.2</td>\n",
       "      <td>16.4</td>\n",
       "      <td>67.4</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>summer</td>\n",
       "      <td>2012</td>\n",
       "      <td>no</td>\n",
       "      <td>saturday</td>\n",
       "      <td>no</td>\n",
       "      <td>clear</td>\n",
       "      <td>16.2</td>\n",
       "      <td>13.2</td>\n",
       "      <td>75.7</td>\n",
       "      <td>10.3</td>\n",
       "      <td>6883</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  season  year holiday   weekday workingday weather  temp  \\\n",
       "days_since_start                                                            \n",
       "231               autumn  2011      no  saturday         no   clear  19.2   \n",
       "490               summer  2012      no  saturday         no   clear  16.2   \n",
       "\n",
       "                  feel_temp  humidity  windspeed  count  \n",
       "days_since_start                                         \n",
       "231                    16.4      67.4        7.0   5191  \n",
       "490                    13.2      75.7       10.3   6883  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Dummy variables for a XGBoost model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>temp</th>\n",
       "      <th>feel_temp</th>\n",
       "      <th>humidity</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>count</th>\n",
       "      <th>season_autumn</th>\n",
       "      <th>season_spring</th>\n",
       "      <th>season_summer</th>\n",
       "      <th>season_winter</th>\n",
       "      <th>...</th>\n",
       "      <th>weekday_saturday</th>\n",
       "      <th>weekday_sunday</th>\n",
       "      <th>weekday_thursday</th>\n",
       "      <th>weekday_tuesday</th>\n",
       "      <th>weekday_wednesday</th>\n",
       "      <th>workingday_no</th>\n",
       "      <th>workingday_yes</th>\n",
       "      <th>weather_clear</th>\n",
       "      <th>weather_light rain</th>\n",
       "      <th>weather_mist</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>days_since_start</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>2011</td>\n",
       "      <td>18.3</td>\n",
       "      <td>15.5</td>\n",
       "      <td>60.5</td>\n",
       "      <td>17.0</td>\n",
       "      <td>5130</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>2011</td>\n",
       "      <td>13.2</td>\n",
       "      <td>9.9</td>\n",
       "      <td>90.6</td>\n",
       "      <td>16.6</td>\n",
       "      <td>2416</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  year  temp  feel_temp  humidity  windspeed  count  \\\n",
       "days_since_start                                                      \n",
       "235               2011  18.3       15.5      60.5       17.0   5130   \n",
       "284               2011  13.2        9.9      90.6       16.6   2416   \n",
       "\n",
       "                  season_autumn  season_spring  season_summer  season_winter  \\\n",
       "days_since_start                                                               \n",
       "235                           1              0              0              0   \n",
       "284                           0              0              0              1   \n",
       "\n",
       "                  ...  weekday_saturday  weekday_sunday  weekday_thursday  \\\n",
       "days_since_start  ...                                                       \n",
       "235               ...                 0               0                 0   \n",
       "284               ...                 0               0                 0   \n",
       "\n",
       "                  weekday_tuesday  weekday_wednesday  workingday_no  \\\n",
       "days_since_start                                                      \n",
       "235                             0                  1              0   \n",
       "284                             0                  1              0   \n",
       "\n",
       "                  workingday_yes  weather_clear  weather_light rain  \\\n",
       "days_since_start                                                      \n",
       "235                            1              1                   0   \n",
       "284                            1              0                   1   \n",
       "\n",
       "                  weather_mist  \n",
       "days_since_start                \n",
       "235                          0  \n",
       "284                          0  \n",
       "\n",
       "[2 rows x 24 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_data.sample(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Model\n",
    "\n",
    "- A linear model\n",
    "- A random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = dummy_data.drop('count', axis=1)\n",
    "y = dummy_data['count']\n",
    "\n",
    "rf_mod = RandomForestRegressor(n_estimators=100)\n",
    "rf_mod.fit(X, y)\n",
    "\n",
    "lm_mod = LinearRegression()\n",
    "lm_mod.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LM: 577.064364441647\n",
      "RF: 169.836853625171\n"
     ]
    }
   ],
   "source": [
    "print('LM:', mean_absolute_error(y, lm_mod.predict(X)))\n",
    "print('RF:', mean_absolute_error(y, rf_mod.predict(X)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Interpretation Methods\n",
    "\n",
    "- Focus is on model-agnostic methods\n",
    "  - First train the model, then work on interpreting it\n",
    "  - Basic idea: Wiggle the input data and measure changes in the predicted output\n",
    "- Model-agnostic methods have a few advantages: (Ribeiro++ 2016)\n",
    "  - Flexible regarding models: You can use any model \"below\" it, as complex as you want.\n",
    "\t- You can replace the ML model anytime (low switching cost), and can compare different models in terms of interpretability. Before, you might have had a unwanted multi-objective optimization between a model that performs better but is less interpretable, and another that performed worse but is better interpretable. Those times are gone!\n",
    "  - Flexible regarding explanations: Different model users might care about different explanations (e.g. ML engineers: feature importance vs. legal dept: feature effects vs. customers: TODO Shapley/LIME/counterfactual examples).\n",
    "  - Flexible regarding feature representations: You can swap out the features between training and interpreting: Train your document classifier with word embeddings, but explain its prediction using a RuleFit algorithm on the actual (interpretable) words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"img/big-picture.png\" style=\"height: 90%\" />\n",
    "\n",
    "Source: Molnar 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Interpretation Methods\n",
    "\n",
    "- As always, the answer to \"which method\" is \"it depends\". What do you want to understand? The global model or a local prediction? Do you only want to understand the importance of each feature, or also the amount of its contribution? Are there constraints from the legal department (must all features be explained? is the main target to avoid minority bias?)?\n",
    "  - Do you want to understand the *global* model behavior, or do you want to explain a *single* data instance and why a specific prediction was made?\n",
    "  - Do you want to understand the *importance* of a feature, or the *effect size* of a feature?\n",
    "\n",
    "----\n",
    "\n",
    "- Global methods that explain global model behavior across all data instances\n",
    "  - Partial Dependence Plots\n",
    "    - feature effect\n",
    "  - Permutation Feature Importance\n",
    "\t- feature importance\n",
    "- Local methods that explain invididual predictions\n",
    "  - Shapley Values\n",
    "\t- feature effect / TODO they can be seen as the feature importance for a single instance too, right?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Permutation Feature Importance\n",
    "\n",
    "- First described in Breiman's 2001 Random Forest paper\n",
    "- Intuition: Molnar pg 301\n",
    "  - In a linear model, the **standardized feature coefficient** (or: p-value) measures the importance of a single feature for the predicted outcome. PFIs are the generalized, model-agnostic version of this.\n",
    "- The feature importance automatically captures interaction effects/importance too\n",
    "- Algorithm\n",
    "  - Shuffle the column of interest\n",
    "  - Predict with true data\n",
    "  - Predict with shuffled data\n",
    "    - /* No retraining of the model necessary! */\n",
    "  - Take difference between losses\n",
    "  - Compute pointwise average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    table.eli5-weights tr:hover {\n",
       "        filter: brightness(85%);\n",
       "    }\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        <table class=\"eli5-weights eli5-feature-importances\" style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto;\">\n",
       "    <thead>\n",
       "    <tr style=\"border: none;\">\n",
       "        <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">Weight</th>\n",
       "        <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "    </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.5492\n",
       "                \n",
       "                    &plusmn; 0.0255\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                year\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 83.03%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.4343\n",
       "                \n",
       "                    &plusmn; 0.0299\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                temp\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 93.49%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.1105\n",
       "                \n",
       "                    &plusmn; 0.0127\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                humidity\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 94.48%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0873\n",
       "                \n",
       "                    &plusmn; 0.0063\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                feel_temp\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 96.26%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0501\n",
       "                \n",
       "                    &plusmn; 0.0073\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                season_spring\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 96.70%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0419\n",
       "                \n",
       "                    &plusmn; 0.0022\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                season_winter\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 96.78%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0404\n",
       "                \n",
       "                    &plusmn; 0.0017\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                windspeed\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 97.14%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0341\n",
       "                \n",
       "                    &plusmn; 0.0072\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                weather_light rain\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.19%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0057\n",
       "                \n",
       "                    &plusmn; 0.0005\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                weather_clear\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.31%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0045\n",
       "                \n",
       "                    &plusmn; 0.0013\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                weekday_sunday\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.31%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0044\n",
       "                \n",
       "                    &plusmn; 0.0012\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                season_summer\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.37%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0039\n",
       "                \n",
       "                    &plusmn; 0.0012\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                weekday_saturday\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.50%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0028\n",
       "                \n",
       "                    &plusmn; 0.0004\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                weekday_monday\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.51%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0027\n",
       "                \n",
       "                    &plusmn; 0.0009\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                workingday_no\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.53%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0026\n",
       "                \n",
       "                    &plusmn; 0.0006\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                workingday_yes\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.62%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0019\n",
       "                \n",
       "                    &plusmn; 0.0001\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                weather_mist\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.66%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0016\n",
       "                \n",
       "                    &plusmn; 0.0005\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                holiday_yes\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.68%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0015\n",
       "                \n",
       "                    &plusmn; 0.0002\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                weekday_friday\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.70%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0014\n",
       "                \n",
       "                    &plusmn; 0.0004\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                weekday_tuesday\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.71%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0013\n",
       "                \n",
       "                    &plusmn; 0.0003\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                holiday_no\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "    \n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 99.71%); border: none;\">\n",
       "                <td colspan=\"2\" style=\"padding: 0 0.5em 0 0.5em; text-align: center; border: none; white-space: nowrap;\">\n",
       "                    <i>&hellip; 3 more &hellip;</i>\n",
       "                </td>\n",
       "            </tr>\n",
       "        \n",
       "    \n",
       "    </tbody>\n",
       "</table>\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ideally you'd compute feature importance on test data\n",
    "\n",
    "rf_perm = PermutationImportance(rf_mod).fit(X, y)\n",
    "\n",
    "eli5.show_weights(rf_perm, feature_names=list(X.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1: Fairness\n",
    "\n",
    "- PFI handle this problem because now you see how much each feature (e.g. gender) contributes to the predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Partial Dependence Plots\n",
    "\n",
    "- First described in Friedman's 2001 Gradient Boosting Machine paper\n",
    "- Intuition: Molnar pg. 301:\n",
    "  - In a linear model, the **feature coefficient** measures the effect of a single feature on the predicted outcome. PDPs are the generalized, model-agnostic version of this.\n",
    "- Algorithm (for categorical variables - most intuitive, for the beginning)\n",
    "  - For each feature value (e.g. spring, summer, autumn, winter):\n",
    "    - Force the entire dataset's `season` to this feature value (e.g. winter)\n",
    "    - Keep all other features the same\n",
    "    - Predict $\\hat{y}$\n",
    "    - Average the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# sklearn.inspection needs sklearn >=0.21\n",
    "\n",
    "from sklearn.inspection import partial_dependence, plot_partial_dependence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['year', 'temp', 'feel_temp', 'humidity', 'windspeed', 'season_autumn',\n",
       "       'season_spring', 'season_summer', 'season_winter', 'holiday_no',\n",
       "       'holiday_yes', 'weekday_friday', 'weekday_monday', 'weekday_saturday',\n",
       "       'weekday_sunday', 'weekday_thursday', 'weekday_tuesday',\n",
       "       'weekday_wednesday', 'workingday_no', 'workingday_yes', 'weather_clear',\n",
       "       'weather_light rain', 'weather_mist'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "seasons = ['season_spring', 'season_summer', 'season_autumn', 'season_winter']\n",
    "PDs = pd.Series(np.nan, index=seasons)\n",
    "for season in seasons:\n",
    "    X_temp = X.copy()\n",
    "    for S in seasons:\n",
    "        X_temp[S] = 0\n",
    "    X_temp[season] = 1\n",
    "    PDs[season] = rf_mod.predict(X_temp).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "season_spring    4635.75\n",
       "season_summer    5521.70\n",
       "season_autumn    5576.21\n",
       "season_winter    5556.99\n",
       "dtype: float64"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PD on 'season', *given* everything else (e.g. temperature) stays the same:\n",
    "PDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "season\n",
       "autumn    5644.303191\n",
       "spring    2604.132597\n",
       "summer    4992.331522\n",
       "winter    4728.162921\n",
       "Name: count, dtype: float64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby('season')['count'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "season\n",
      "autumn    5634.686011\n",
      "spring    2626.843978\n",
      "summer    5018.850652\n",
      "winter    4714.693708\n",
      "Name: yhat, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "data['yhat'] = rf_mod.predict(X)\n",
    "print(data.groupby('season')['yhat'].mean())\n",
    "data.drop('yhat', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why are the PDs so different from the group means?\n",
    "\n",
    "- Here, we use *every* instance for every category\n",
    "- Here, we evaluate a model, i.e. the *predictions* for $\\hat{y}$, and the effect on *them*\n",
    "- But most importantly:\n",
    "- Feature interactions are marginalized out:\n",
    "  - Group means of `winter` contain only observations with -10°C\n",
    "  - Manipulated data contains observations with +30°C and manipulated season `winter`\n",
    "  - $\\Rightarrow$ The *pure* effect of season is not so high\n",
    "\n",
    "This becomes clear once we compute ICEs, i.e. a PDP for *one* observation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "season_spring    4635.75\n",
       "season_summer    5521.70\n",
       "season_autumn    5576.21\n",
       "season_winter    5556.99\n",
       "dtype: float64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 234\n",
    "one_obs = X.iloc[i:(i+1), :]  # weird syntax keeps it a DF instead of a Series\n",
    "\n",
    "seasons = ['season_spring', 'season_summer', 'season_autumn', 'season_winter']\n",
    "PDs = pd.Series(np.nan, index=seasons)\n",
    "for season in seasons:\n",
    "    one_obs_temp = one_obs.copy()\n",
    "    for S in seasons:\n",
    "        one_obs_temp[S] = 0\n",
    "    one_obs_temp[season] = 1\n",
    "    PDs[season] = rf_mod.predict(one_obs_temp).mean()\n",
    "\n",
    "# PD on 'season', *given* everything else (e.g. temperature) stays the same:\n",
    "PDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# small vertical lines are the data's deciles\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(12,5))\n",
    "\n",
    "plot_partial_dependence(lm_mod, X, features=[1, 3, (1, 3)],\n",
    "                       grid_resolution=25, percentiles=(0, 1), n_jobs=4,\n",
    "                       feature_names=X.columns, fig=fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 3, figsize=(12,5))\n",
    "\n",
    "\n",
    "plot_partial_dependence(rf_mod, X, features=[1, 3, (1, 3)],\n",
    "                       grid_resolution=25, percentiles=(0, 1), n_jobs=4,\n",
    "                       feature_names=X.columns, fig=fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here you see the main problem in linear models: They assume a linear relationship with temperature.\n",
    "\n",
    "- 5°C: 200 bikes\n",
    "- 10°C: 400 bikes\n",
    "- $\\Rightarrow$ 50°C: 2000 bikes!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Problem 2: Understanding\n",
    "\n",
    "PDPs are one solution to this problem because we obtain the marginalized feature effect for each feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Shapley Values\n",
    "\n",
    "https://christophm.github.io/interpretable-ml-book/shap.html\n",
    "\n",
    "# NOTE/TODO: the shap package implements SHAP, a newer method based on Shapley Values\n",
    "\n",
    "https://github.com/slundberg/shap\n",
    "\n",
    "- A bit more complex to compute\n",
    "- But: There are many other cool measures and plots based on Shapley values\n",
    "- Once you understand them, you can use the principle for your entire interpretability suite!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing Shapley values\n",
    "\n",
    "- Based on game theory:\n",
    "  - TODO\n",
    "- Algorithm\n",
    "  - TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explain the model's predictions using SHAP values\n",
    "# (same syntax works for LightGBM, CatBoost, and scikit-learn models)\n",
    "explainer = shap.TreeExplainer(rf_mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sub = X.sample(100, random_state=20190818)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values = explainer.shap_values(X_sub)  # takes long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load JS visualization code to notebook\n",
    "shap.initjs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Shapley Values\n",
    "\n",
    "- Visualize Shapley Values as *forces*\n",
    "- They move the prediction away from the *base value* (the average prediction over all instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_mod.predict(X).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "i = 20\n",
    "# visualize the first prediction's explanation (use matplotlib=True to avoid Javascript)\n",
    "shap.force_plot(explainer.expected_value, shap_values[i,:], X_sub.iloc[i,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Shapley-based feature importance\n",
    "\n",
    "- A simple measure of feature importance is the average *absolute* Shapley value for each feature\n",
    "- These plots are an alternative to permutation feature importance discussed earlier. But:\n",
    "- There is a big difference between both importance measures: Permutation feature importance is based on the decrease in model performance. SHAP is based on magnitude of feature attributions.\n",
    "  - https://christophm.github.io/interpretable-ml-book/shap.html#shap-feature-importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, X_sub, plot_type=\"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# SHAP dependence plot\n",
    "\n",
    "SHAP feature dependence might be the simplest global interpretation plot: \n",
    "\n",
    "1. Pick a feature.\n",
    "2. For each data instance, plot a point with the feature value on the x-axis and the corresponding Shapley value on the y-axis.\n",
    "\n",
    "----\n",
    "\n",
    "- These plots are an alternative to partial dependence plots discussed earlier. But:\n",
    "- While PDP and ALE plot show average effects, SHAP dependence also shows the variance on the y-axis. Especially in case of interactions, the SHAP dependence plot will be much more dispersed in the y-axis. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: the color shows the *interaction* with season_spring. Disable it for the talk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# create a SHAP dependence plot to show the effect of a single feature across the whole dataset\n",
    "shap.dependence_plot(\"humidity\", shap_values, X_sub)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Problem 3: Explainability\n",
    "\n",
    "- Shapley Values or SHAP or LIME or Counterfactual Examples TODO solve this problem because TODO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Other methods not covered here\n",
    "\n",
    "- Other global models\n",
    "  - ALEs, because PDPs suffer when features are correlated\n",
    "- Other local, i.e. example-based methods\n",
    "  - Counterfactual Explanations\n",
    "\t - We tend to think in counterfactual cases. If we apply for a loan and get rejected, the best explanation for a human would be something like \"if you earned 10'000€ more AND if you had paid that electricity bill in 2010, you'd been low-risk\" (Molnar pg. 36-37)\n",
    "\t - A counterfactual explanation is the \"smallest change\" to the feature values that changes the prediction to a predefined output (Molnar pg. 241)\n",
    "  - Adversarial Expamples\n",
    "     - TODO lightning talk?\n",
    "\t - An adversarial example is an (artificial) instance with small changes in the features, that trick the model into making a false prediction.\n",
    "\t - https://christophm.github.io/interpretable-ml-book/images/adversarial-turtle.jpg\n",
    "\t   - This turtle looks like a rifle from many angles and zoom levels.\n",
    "       - It's not a big leap now to design a rifle that gets classified as a turtle.\n",
    "\t - Adversarial examples make the ML model vulnerable to attacks. If you know them, you can use them in an updated training set. If your opponent knows them, he can get a loan, pass your gun detection AI, or make your car run over a stop sign (there are stickers for that)\n",
    "\n",
    "----\n",
    "\n",
    "- Refer to Molnar 2019 for everything"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# The Future of Interpretable Machine Learning\n",
    "\n",
    "- ML will grow because it *automatizes* decision making, and everyone likes automatization\n",
    "- IML helps through:\n",
    "\t - Hesitant adaptors that want predictions explained and demand some transparency (also due to legal reasons)\n",
    "     - We need IML because we are never able to perfectly specify our goal to the computer. He stupidly does *exactly* what we tell him to. (Molnar pg 296). You specify an imperfect or a proxy goal (e.g. corporation: maximize profit for shareholders), and the \"system\" (e.g. model) might find a solution you didn't want (e.g. through imperfect training data).\n",
    "- IML can be used to reverse engineer or game a model. Credit score models are better left uninterpreted (for the public), because people that still stay a risky debtor can just give back two credit cards to increase their score. This works for features that have a correlation influence (not causation influence) on the target. *Causal* features are not gameable. (pg. 25 Molnar)\n",
    "- As I said, It's a relatively new field of research. Things change, papers come at high speed.\n",
    "  - One step forward: The SIPA paper\n",
    "  - Many interpretation methods operate with the same workflow.\n",
    "  - Scholbeck et al. (2019) summarized it into *the SIPA framework*\n",
    "     - Sampling\n",
    "       - You'll be predicting /a lot/. If the prediction function takes too long, use just a sample of your data\n",
    "     - Intervention\n",
    "       - Change some feature values in input data\n",
    "       - Memorable metaphor: Permuted instances as \"Frankenstein's Monster\" (Molnar pg 231)\n",
    "     - Prediction\n",
    "       - Predict y using the intervened data\n",
    "     - Aggregation\n",
    "       - E.g. average local predictions (ICEs) to global ones (PDs)\n",
    "- Adversarial Machine Learning is a new field in Cybersecurity. More ML models deployed IRL, more entry points for attacks. (Biggio++ 2018)\n",
    "\t- Use IML to understand the weaknesses in your models. Be one step ahead of your competition.\n",
    "- Model-agnostic methods will grow because of aforementioned flexibility.\n",
    "- Like ML, IML will be automatized in the future (molnar pg 299). Like a test suite that runs after every code build, every retrained model gets an automatic report of feature importance, PDPs, a few surrogate models, etc.\n",
    "- We won't die out, though. Today anyone can build websites without HTML, CSS, JS, but we still need web developers. Tomorrow, anyone can train a ML model, but we'll still need ML experts. (molnar pg 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![end](img/end.jpg)\n",
    "\n",
    "- <img src=\"img/twitter.svg\" style=\"height: 20px; float: left\" /> &nbsp; @eng_elhardt\n",
    "- <img src=\"img/github.svg\" style=\"height: 20px; float: left\" /> &nbsp; AlexEngelhardt (slides: https://github.com/AlexEngelhardt/iml-talk)\n",
    "- Longer blog post available at https://www.alpha-epsilon.de/blog/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "   - Molnar, Christoph. \"Interpretable machine learning. A Guide for Making Black Box Models Explainable\", 2019. https://christophm.github.io/interpretable-ml-book/.\n",
    "   - Scholbeck CA, Molnar C, Heumann C, Bischl B, Casalicchio G (2019). Sampling, Intervention, Prediction, Aggregation: A Generalized Framework for Model Agnostic Interpretations. https://arxiv.org/abs/1904.03959\n",
    "   - Doshi-Velez, Finale, and Been Kim. “Towards a rigorous science of interpretable machine learning,” no. Ml: 1–13. http://arxiv.org/abs/1702.08608 (2017).\n",
    "   - Ribeiro, Marco Tulio, Sameer Singh, and Carlos Guestrin. \"Model-agnostic interpretability of machine learning.\" https://arxiv.org/pdf/1606.05386 (2016).\n",
    "   - Biggio, Battista, and Fabio Roli. \"Wild patterns: Ten years after the rise of adversarial machine learning.\" Pattern Recognition 84 (2018): 317-331. https://arxiv.org/pdf/1712.03141\n",
    "   - Roscher, Ribana, et al. \"Explainable Machine Learning for Scientific Insights and Discoveries.\" (2019). https://arxiv.org/pdf/1905.08883.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Bonus Slides\n",
    "\n",
    "### IML on training or test data?\n",
    "\n",
    "- Molnar pg. 194 (online: chap 5.5.2)\n",
    "- tl;dr: It depends on what you want to know\n",
    "- Imagine an overfitted SVM with 100 garbage features.\n",
    "  - What feature importance would you expect? \n",
    "    - Zero because the features are noise? $\\Rightarrow$ use test data\n",
    "    - Or should they reflect how much the model depends on each feature? $\\Rightarrow$ use training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Bonus Slides\n",
    "\n",
    "### Correlations in features\n",
    "\n",
    "- If features are correlated, partial dependence plots will be computed with unrealistic instances\n",
    "- e.g. `temp = 20` degrees, but `feel_temp = -5`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "sns.scatterplot('temp', 'feel_temp', data=data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "- wat do?\n",
    "- A method called *Accumulated Local Effects* (ALEs) is unbiased then\n",
    "- See Molnar 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
